
\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{natbib}
\usepackage{url}

\let\code=\texttt

\newcommand{\opand}{\mathbin{\rm and}}

\begin{document}

\title{Design of an R function to do Limiting Conditional Models
for Generalized Linear Models and Log-Linear Models}

\author{Charles J. Geyer}

\maketitle

<<options,include=FALSE,echo=FALSE>>=
options(keep.source = TRUE, width = 60)
@

\section{Introduction}

This is the design document for an R function to fit generalized linear
models that are discrete exponential families and log-linear models for
contingency tables (all of which are exponential families) and do the
right thing when the solution is ``at infinity'' \citep{geyer-gdor}.

\begin{itemize}
\item
When the family is specified to be \code{"poisson"} (unlike R function
\code{glm} only a character string value of this argument is allowed)
our function should work just like R function \code{glm} with argument
\code{family = "poisson"} (so the link function is automatically the
default log link) except that when the maximum likelihood estimate does
not exist in the conventional sense (the solution is ``at infinity'')
our function finds a generalized direction of recession (GDOR)
\citep{geyer-gdor},
fits the limiting conditional model (LCM) \citep{geyer-gdor}, and
returns an object of class \code{c("lcm", "glm", "lm")} that includes
the GDOR and the LCM model fit.
\item
When the family is specified to be \code{"binomial"} (unlike R function
\code{glm} only a character string value of this argument is allowed)
our function should work just like R function \code{glm} with argument
\code{family = "binomial"} (so the link function is automatically the
default logit link) except that when the maximum likelihood estimate does
not exist in the conventional sense (the solution is ``at infinity'')
our function finds a GDOR, fits the LCM, and
returns an object of class \code{c("lcm", "glm", "lm")} that includes
the GDOR and the LCM model fit.

Like R function \code{glm} our function should handle both Bernoulli response
(the response vector is zero-or-one-valued) or general binomial response
(the response ``vector'' is actually a two-column matrix of counts, the
first column the count of successes for each case and the
second column the count of failures for each case).
\item
When the family is specified to be \code{"multinomial"} our function should
fit the models described in Section~8.1 of \citet{agresti}.

Like R function \code{multinom} in R package \code{nnet}, which is a so-called
recommended package that is installed by default in every installation of R,
our function should handle both factor response (the response vector is an
R object of class \code{"factor"}) or general multinomial response
(the response ``vector'' is actually a matrix of counts, each column the count
for one category of the categorical response).
\end{itemize}

\section{Alligators}
\label{sec:alligators}

For an example of multinomial regression we will use the alligator food
choice from \citet[Table~8.1]{agresti}
<<alligator-data>>=
library("CatDataAnalysis")
data("table_8.1")
names(table_8.1)
@
In these data the response vector is \code{count} and the categories of
response are \code{food}, which is categorical
<<alligator-data-response-categories>>=
sapply(table_8.1, class)
sapply(table_8.1, max)
@
We guess these integer values are in the order they occur in the table
published in the book.
<<alligator-data-fixup>>=
table_8.1 <- transform(table_8.1,
    lake = c("Hancock", "Oklawaha", "Trafford", "George")[lake])
table_8.1 <- transform(table_8.1,
    gender = c("Male", "Female")[gender])
table_8.1 <- transform(table_8.1,
    size = c("less_than_2.3", "greater_than_2.3")[size])
table_8.1 <- transform(table_8.1,
    food = c("Fish", "Invertebrate", "Reptile", "Bird", "Other")[food])
sapply(table_8.1, class)
@

We check that we have some data values shown in the table correct
<<alligator-data-fixup-check>>=
subset(table_8.1, lake == "Hancock" & gender == "Male"
    & size == "less_than_2.3")
subset(table_8.1, lake == "George" & gender == "Female"
    & size == "greater_than_2.3")
@
Seems like we are OK in that we have gotten the first and last lines of the
table in the book correct.  We could, of course, check some other lines
if we thought we needed to.

We know (\citealp[Section~2.1.5]{agresti}; \citealp[Section~7]{expfam})
that we can fit the model assuming
Poisson sampling, multinomial sampling or product-multinomial sampling and
convert the results from one sampling scheme to the other.

Officially, our model is product-multinomial.  Every sum over the food
category (for each possible values of the other variables) is fixed rather
than random.  Another way of saying this is that the
\code{lake:gender:size} margin is fixed.

This means we must have \code{lake:gender:size} in the formula for every
model we fit if we use Poisson sampling.  And if we are thinking the formula
has some expression \code{foo} on the right-hand side, we need to have
\code{food:foo} in our formula if we use Poisson sampling.
For example, the models fit in Table~8.2 of \citet{agresti} are
<<fit-models>>=
f <- c(null = "", g = "gender", s = "size", l = "lake",
    ls = "lake + size", lsg = "lake + size + gender")
ff <- sapply(f, function(x) {
    if(grepl("+", x, fixed = TRUE)) x <- paste0("(", x, ")")
    if(x != "") x <- paste0(":", x)
    paste0("count ~ lake:gender:size + food", x)
})
cbind(ff)
mm <- lapply(ff, function(x) glm(as.formula(x),
    family = "poisson", data = table_8.1))
Gsq <- sapply(mm, function(x) x$deviance)
Xsq <- sapply(mm, function(x) {
    o <- x$y
    e <- x$fitted.values
    sum((o - e)^2 / e)
})
df <- sapply(mm, function(x) x$df.residual)
foo <- data.frame(Gsq, Xsq, df)
@

\pagebreak[3]
The following should match part of Table~{8.2} in \citet{agresti}.
And it does.
<<fit-models-output>>=
print(foo, digits = 3)
@

Now we ignore all but the \code{lake + size} model
<<model-ls-observed>>=
xtabs(count ~ size + food + lake, data = table_8.1)
@
OK.  But we want to reorder the factor levels so it agrees with the book.
<<model-ls-observed>>=
table_8.1 <- transform(table_8.1, lake = factor(lake,
    levels = c("Hancock", "Oklawaha", "Trafford", "George")))
table_8.1 <- transform(table_8.1, size = factor(size,
    levels = c("less_than_2.3", "greater_than_2.3")))
table_8.1 <- transform(table_8.1, food = factor(food,
    levels = c("Fish", "Invertebrate", "Reptile", "Bird", "Other")))
xtabs(count ~ size + food + lake, data = table_8.1)
@
That agrees with the counts (numbers not in parentheses) in Table~{8.3}
in \citet{agresti}.  Now we try for estimated expected counts (numbers
in parentheses).
<<model-ls-expected>>=
m <- mm$ls
e <- m$fitted.values
print(xtabs(e ~ size + food + lake, data = table_8.1),
    digits = 1)
@
OK.  So what is wanted is a more convenient way to fit models like this.

\section{Alligators Redo}

We try using R function \code{multinom} in R package \code{nnet},
which is a ``recommended'' package installed by default in all installations
of R.

For this we need to reshape the data.
<<alligators-reshape>>=
resp <- unstack(table_8.1, count ~ food)
pred <- subset(table_8.1, food == "Fish")
dim(resp)
dim(pred)
colnames(resp)
colnames(pred)
resp <- as.matrix(resp)

library(nnet)
mout <- multinom(resp ~ lake + size + gender, data = pred)
summary(mout)
@

\section{Design for Product Multinomial}

\subsection{Matrix Response}

So one design is just like that of R function \code{multinom}.
The response is a matrix.  The formula is ``crossed'' with the variable
that is the column labels of this matrix, and the joint distribution of the
data is Poisson conditioned on the row sums of this matrix.

\subsection{Factor Response}

This is also implemented by R function \code{multinom}.
The response is a factor.  The formula is ``crossed'' with this factor,
and the joint distribution of the data is Poisson conditioned on number
of cases having each level of this factor being fixed.

\subsection{Vector Response, Explicit Crossing and Conditioning}

Alternatively, we can have a design that works like the analysis of
Section~\ref{sec:alligators} above.  Now the response vector is just the
vector of counts in all cells of the contingency table, the same as it was
in Section~\ref{sec:alligators} above.

Now the conditioning is explicit.  It could be specified by either a factor
or a formula that yields a model matrix that has zero-or-one-valued components
and row sums equal to one.  For example, for the analysis of
Section~\ref{sec:alligators} above, we could use the formula
\begin{verbatim}
conditioning = ~ 0 + lake:gender:size
\end{verbatim}
The ``\code{0 +}'' is important.  Without it, we would not have a model
matrix (for this formula) with row sums equal to one.

And the ``crossing'' is also explicit.  For example, for the analysis of
Section~\ref{sec:alligators} above, we could use the formula
\begin{verbatim}
crossing = food
\end{verbatim}

This design is so tricky, we leave it out of the initial implementation.

\section{Solutions at Infinity}

\subsection{Theory}

From Section~3.9 of \citet{geyer-gdor} we see that if $y$ is the response vector
and $M$ is the model matrix, then $M^T y$ is the submodel canonical sufficient
statistic vector.  Theorems 1, 3, and {4} in \citet{geyer-gdor} say that the
maximum likelihood estimate (MLE) exists for the submodel canonical parameter
vector (called the coefficients vector by R function \code{glm})
if and only if every direction of recession of the log likelihood is also
a direction of constancy, where if $Y$ denotes a random realization of the
response vector and $y$ the observed value of the response vector, a vector
$\delta$ in the submodel canonical parameter space is
\begin{itemize}
\item a \emph{direction of recession} if $(Y - y)^T M \delta \le 0$
    almost surely and
\item and a \emph{direction of constancy} if $(Y - y)^T M \delta = 0$
    almost surely.
\end{itemize}

Suppose $\delta$ is a direction of recession
and define $\eta = M \delta$.  Then by definition of direction of recession,
we have $Y^T \eta \le y^T \eta$ almost surely.
\begin{itemize}
\item If $\eta_j = 0$, this says nothing about $Y_j$.
\item If $\eta_j < 0$, this says $Y_j \ge y_j$ almost surely because it
    is possible that all coordinates of $Y$ are zero except for $Y_j$.
    And this implies $y_j = 0$ because it it possible for $Y_j$ to be zero.
\item If $\eta_j > 0$, this says $Y_j \le y_j$ almost surely, and this is
    impossible because $Y_j$ can take arbitrarily large values.  Thus this
    case in not allowed.
\end{itemize}
Thus for any direction of recession $\eta$ we must have all coordinates
nonpositive, and we must have $\eta_j < 0$ implies $y_j = 0$.


\subsection{Poisson}


\begin{thebibliography}{}

\bibitem[Agresti(2013)]{agresti}
Agresti, A. (2013).
\newblock \emph{Categorical Data Analysis}, third edition.
\newblock John Wiley \& Sons, Hoboken.

\bibitem[Geyer(2009)]{geyer-gdor}
Geyer, C.~J. (2009).
\newblock Likelihood inference in exponential families and directions of
    recession.
\newblock \emph{Electronic Journal of Statistics}, \textbf{3}, 259--289
    (electronic).

\bibitem[Geyer(2016a)]{expfam}
Geyer, C.~J. (2016a).
\newblock Stat 5421 Lecture Notes: Exponential Families, Part I.
\newblock \url{http://www.stat.umn.edu/geyer/5421/notes/expfam.pdf}.

\bibitem[Geyer(2016b)]{infinity}
Geyer, C.~J. (2016b).
\newblock Stat 5421 Lecture Notes: Exponential Families, Part II.
\newblock \url{http://www.stat.umn.edu/geyer/5421/notes/infinity.pdf}.

\end{thebibliography}

\end{document}

