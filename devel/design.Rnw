
\documentclass[11pt]{article}

\usepackage{indentfirst}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{natbib}

\newcommand{\set}[1]{\{\, #1 \,\}}

\newcommand{\y}{\texttt{y}}
\newcommand{\x}[1]{\texttt{x#1}}

\begin{document}

\title{Design Document for R package GLMBB}

\author{Charles J. Geyer}

\maketitle

<<options,include=FALSE,echo=FALSE>>=
options(keep.source = TRUE, width = 60)
@

\section{R Models}

What is an R model?  It depends on what function is doing the fitting.
We are interested in models fitted by the R function \texttt{glm}.
All of the arguments to the function affect what model is fitted, but
we are interested on various models that hold everything but the formula
fixed.  So in this context, different models have different formulas.

Underneath the hood models are specified by terms objects.  Here is an
example
<<terms-example-big>>=
terms.big <- terms(y ~ x1 * x2 * x3 * x4)
terms.big
@

\subsection{Nested Models}

We say models $m_1$ and $m_2$ are \emph{nested} if every term in $m_1$
appears in $m_2$ and, if $m_1$ has an intercept, then either $m_2$
has an intercept or it has a categorical predictor (so intercepts
are irrelevant).
By ``term'' here we mean what the terms object is calling a term,
corresponding to a column of the \texttt{"factors"} attribute (if any)
or to a component of the \texttt{term.labels} attribute.
By ``categorical'' variable we mean what R calls a variable of class
\texttt{"factor"}.

For simplicity we are going to enforce a discipline that all models
have intercept or no models have intercept.  It makes things a lot
simpler.

Here are some examples of models nested within our previous example.
<<terms-example-littlest>>=
terms.little <- terms(~ 1)
terms.little
terms.middle <- terms(~ x3 + x2 * x1)
terms.middle
@
We see the variables can be out of order so the term names do not match.
We see the row dimension of the \texttt{"factors"} attribute can differ
because of having or not having the response in the formula and having
or not having various predictors.  We also see that in the extreme
case the \texttt{"factors"} attribute need not be a matrix.  It is
just \texttt{numeric(0)} when there are no predictor variables in the model.

Since working with the matrices or non-matrices seems to be difficult,
we work on the term labels.  But we have to deal with the ordering.
<<standardize-term-labels>>=
standardize.term.labels <- function(foo) {
    stopifnot(is.character(foo))
    bar <- strsplit(foo, split = ":")
    baz <- lapply(bar, sort)
    sapply(baz, paste, collapse = ":")
}
term.labels.big <- attr(terms.big, "term.labels")
term.labels.little <- attr(terms.little, "term.labels")
term.labels.middle <- attr(terms.middle, "term.labels")
all(term.labels.little %in% term.labels.big)
all(term.labels.middle %in% term.labels.big)
all(standardize.term.labels(term.labels.middle) %in%
    standardize.term.labels(term.labels.big))
@

\subsection{Hierarchical Models}

A model is \emph{hierarchical} if every for every interaction term
there are all lower-order interactions and main effects for its variables.
In terms of the \texttt{"factors"} attribute, it is
\begin{itemize}
\item \texttt{numeric(0)}
\item or every column that contains more than one one (is an interaction term)
    when any one of its ones is changed to a zero matches another column.
\end{itemize}

\section{The Problem}

Define a partial order on models by $m_1 \lesssim m_2$ if $m_1$ is nested
within $m_2$.  Let $\mathcal{M}$ denote the family of all possible models
(fitted with \texttt{glm} with all arguments except \texttt{formula} the
same and with all formulas having intercept or all not having intercept).

We are interested in subfamily of the form
\begin{equation} \label{eq:subfamily}
   \mathcal{M}(m_1, m_2)
   =
   \set{ m \in \mathcal{M} : m_1 \lesssim m \lesssim m_2 }
\end{equation}
where $m_1$ and $m_2$ are elements of $\mathcal{M}$
such that $m_1 \lesssim m_2$ so \eqref{eq:subfamily} is nonempty.

We want to find the model within \eqref{eq:subfamily} that has the
minimum value of some information criterion (AIC, BIC, or AICc).
More generally we want to find all of the models within \eqref{eq:subfamily}
whose information criterion exceeds the minimum by a specified ``cutoff.''

\section{The Branch and Bound Algorithm}

The branch and bound algorithm \citep{hand} works as follows.
Let $c$ denote the cutoff and $v$ the minimum value of the criterion
for all models fit so far.  Before any models have been fitted, we
set $v$ to be \texttt{Inf}.

For any model $m$ let $d(m)$ denote the deviance (minus twice the log
likelihood) and let $p(m)$ denote the penalty the information criterion.
For AIC the penalty is $2 p$, where $p$ is the number of estimable parameters
in the model.
For BIC the penalty is $\log(n) p$, where $n$ is the number of cases in
the data (the length of the response vector).
For AICc the penalty is $2 p + 2 p (p + 1) / (n - p - 1)$.

We define a function $f(m_1, m_2)$ that is callable recursively
(as are all R functions) that does the following.
\begin{enumerate}
\item
If $m_1 = m_2$ we are done.  It is the only model in the subfamily.
Fit $m_1$ (in the process adjusting $v$).  Then return (no value is
returned; $f$ does have the side effect of fitting whatever
models it fits and adjusting $v$ correspondingly).

\item
If $m_1 \neq m_2$, fit both $m_1$ and $m_2$.  We know every model in
the subfamily \eqref{eq:subfamily} has deviance no larger than $d(m_2)$
and penalty no larger than $p(m_1)$, hence information criterion no
larger than $d(m_2) + p(m_1)$.

\begin{enumerate}

\item Hence if $v + c < d(m_2) + p(m_1)$ we are done.  No model in this family
can be below the cutoff.
So return (again, $f$ has no value only side effects).

\item Otherwise, when $v + c \ge d(m_2) + p(m_1)$, there is still work to do.
Find a term that is in $m_2$ but not in $m_1$ (there is one
because $m_1 \neq m_2$).  Let $m_2^-$ denote $m_2$ with this term deleted
and $m_1^+$ denote $m_1$ with this term added.
Then $\mathcal{M}(m_1^+, m_2)$ and $\mathcal{M}(m_1, m_2^-)$
partition $\mathcal{M}(m_1, m_2)$.
Hence all of the remaining work is to fit all of the models in them.
Do that: call $f(m_1^+, m_2)$ and $f(m_1, m_2^-)$.
We are now done.
So return (again, $f$ has no value only side effects).

\end{enumerate}
\end{enumerate}

The recursive nature of the function (it calling itself twice in step (b))
hides a lot of work and makes the function much easier to program.
There is a tricky bit in step (b).  Model $m_1^+$ is obvious.  We just
add one term to $m_1$.  But the model $m_2^-$ is not so obvious.  The
hierarchy principle requires that if we delete a term we also delete
all terms containing it.  For example if we delete $\x{1} * \x{2}$,
we must also delete all higher-order interactions containing these variables.

In terms of R terms objects, if the \texttt{"factors"} component of
$m_2$ is the matrix \texttt{m2} and we are trying to delete the term
corresponding to \verb@m2[ , j]@, then we must also delete the terms
corresponding to \verb@m2[ , i]@ such that
\begin{verbatim}
   all(m2[ , j] <= m2[ , i])
\end{verbatim}

The main issue remaining is when we futz around with terms objects to
construct terms objects for $m_1^+$ and $m_2^-$, how do we do it and
obtain valid terms objects that the R function \texttt{model.matrix}
will not object to when we try to make the model matrices that the
R function \texttt{glm.fit} requires?

\section{More on Models}

So let's try it.
<<data>>=
mf <- as.data.frame(HairEyeColor)
names(mf)
dim(mf)
sapply(mf, class)
big <- Freq ~ Hair * Eye * Sex
little <- ~ 1
mtl <- terms(little)
mtb <- terms(big)
term.labels.big <- standardize.term.labels(attr(mtb, "term.labels"))
term.labels.little <- standardize.term.labels(attr(mtl, "term.labels"))
term.labels.diff <- setdiff(term.labels.big, term.labels.little)
the.term <- term.labels.diff[1]
the.term
@

So now we need to add this term to $m_1$ and delete it from $m_2$.
So can we just add this to $m_1$?
Oh!  Update formulas not terms objects using the R function
\texttt{update.formula}.
<<m1-plus-try1>>=
little.plus <- update(little, paste("~ . +", the.term))
little.plus
@
That worked.  Now going down?
<<m2-minus-try1>>=
outies <- grep(the.term, term.labels.big, value = TRUE)
outies
outies <- paste(outies, collapse = " - ")
big.minus <- update(big, paste("~ . -", outies))
big.minus
@
Hmmmmm.  It's not smart enough to convert the whole right-hand side
to \verb@Eye*Sex@.  I guess we're stuck with that.

Actually, in debugging we found out that the above design was completely
wrong.
<<oopsie>>=
the.term <- "Eye:Sex"
outies <- grep(the.term, term.labels.big, value = TRUE)
outies
@
That's wrong; \texttt{outies} should also have the three-way interaction.
Have to work harder.
<<oopsie-fixup>>=
the.term.re <- unlist(strsplit(the.term, split = ":"))
the.term.re <- paste(the.term.re, collapse = ".*")
the.term.re
outies <- grep(the.term.re, term.labels.big, value = TRUE)
outies
@

One more thing.  We have to figure out how to put the response onto
the little formula (since the documentation says it doesn't need one
in the formula input).
<<paste>>=
as.character(~ u + v)
as.character(y ~ u + v)
@
It's weird what happens here, but actually convenient for what we want to do.
<<paste-cont>>=
little.char <- as.character(little)
big.char <- as.character(big)
# this makes it one-sided
if (length(little.char) == 2) {
    little.char <- c(big.char[2], little.char)
} else {
    little.char <- c(big.char[2], little.char[c(1, 3)])
}
little.char <- paste(little.char, collapse = " ")
little <- as.formula(little.char)
little
@
Seems to work.  Let's check that it also works when \texttt{little} has
a left-hand side.
<<paste-too>>=
little <- fred ~ 1
<<paste-cont>>
@

\begin{thebibliography}{}

\bibitem[Hand(1981)]{hand}
Hand, D. J. (1981).
\newblock Branch and bound in statistical data analysis.
\newblock \emph{The Statistician}, \textbf{30}, 1--13.

\end{thebibliography}

\end{document}

